bootstrap.servers: "pkc-419q3.us-east4.gcp.confluent.cloud:9092"
#key.serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
#value.serializer: io.confluent.kafka.serializers.KafkaJsonSerializer
#value.serializer: io.confluent.kafka.serializers.json.KafkaJsonSchemaSerializer
schema.registry.url: "https://psrc-4r3n1.us-central1.gcp.confluent.cloud"
schema.registry.basic.auth.user.info: "<YOUR_API_KEY>:<YOUR_API_SECRET>"
basic.auth.credentials.source: "USER_INFO"
sasl.mechanism: "PLAIN"
sasl.jaas.config: "org.apache.kafka.common.security.plain.PlainLoginModule   required username='<YOUR_USER_ACCOUNT>'   password='<ACCOUNT_PASSWORD>';"
security.protocol: "SASL_SSL"
client.dns.lookup: "use_all_dns_ips"
acks: "all"
enable.idempotence: "true"
transactional.id: "testTrans-2"
consume.group.id: "oncepgroup-id"
consume.enable.auto.commit: "false"
consume.isolation.level: "read_committed"
application.id: "heinz_transact"
processing.guarantee: "exactly_once_v2"

default.value.serde: "io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde"
default.key.serde: "io.confluent.kafka.serializers.json.KafkaJsonSchemaDeserializer"
#default.key.serde:

new.topic: "topic.avro.transaction.dup.avro.key"
orig.topic: "topic.avro.transaction"
dup.topic: "topic.avro.transaction.dup"








# REST listening port for POST Request
server:
  port: 9099

logging:
  level:
    root: INFO
    io.confluent.heinz: ERROR
    org.apache.kafka.clients.FetchSessionHandler: ERROR
    io.confluent.heinz.restController: INFO
    io.confluent.heinz.KafkaSession: INFO
